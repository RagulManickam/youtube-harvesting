{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit_option_menu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBqtCji_FdMF",
        "outputId": "5aaa6c05-c1d3-4782-bae9-0beb2fb69f26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit_option_menu\n",
            "  Downloading streamlit_option_menu-0.4.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting streamlit>=1.36 (from streamlit_option_menu)\n",
            "  Downloading streamlit-1.40.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit>=1.36->streamlit_option_menu)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit>=1.36->streamlit_option_menu)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.36->streamlit_option_menu) (6.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit_option_menu) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit_option_menu) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit_option_menu) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit_option_menu) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit_option_menu) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit_option_menu) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit_option_menu) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit_option_menu) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit_option_menu) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit_option_menu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit_option_menu) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit_option_menu) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.36->streamlit_option_menu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.36->streamlit_option_menu) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit_option_menu) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=1.36->streamlit_option_menu) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit_option_menu) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit_option_menu) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit_option_menu) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit_option_menu) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.36->streamlit_option_menu) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=1.36->streamlit_option_menu) (1.16.0)\n",
            "Downloading streamlit_option_menu-0.4.0-py3-none-any.whl (829 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.3/829.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.40.2-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit, streamlit_option_menu\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.40.2 streamlit_option_menu-0.4.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mysql-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS4gH0lGFjxv",
        "outputId": "435841cc-b5be-495c-9918-3dfd984050dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Downloading mysql_connector_python-9.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-9.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MkAfMorFw6E",
        "outputId": "57beae28-5645-4abd-bd56-818f4636563a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbmAKkhAE3X8",
        "outputId": "8d14f06b-7da6-4181-9a2f-addb9341fef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-02 13:25:31.631 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "import mysql.connector as sql\n",
        "import pymongo\n",
        "from googleapiclient.discovery import build\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SETTING PAGE CONFIGURATIONS\n",
        "icon = Image.open(\"/content/drive/MyDrive/guvi capstone projects/youtube harvesting/logo .png\")\n",
        "st.set_page_config(page_title= \"Youtube Data Harvesting and Warehousing | By Ragul Manickam\",\n",
        "                   page_icon= icon,\n",
        "                   layout= \"wide\",\n",
        "                   initial_sidebar_state= \"expanded\",\n",
        "                   menu_items={'About': \"\"\"# This app is created by *Ragul Manickam!*\"\"\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxzIO13cF2gU",
        "outputId": "6d559c5c-119f-4513-c7a2-46e3e9d3a9ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-02 13:25:37.125 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING OPTION MENU\n",
        "with st.sidebar:\n",
        "    selected = option_menu(None, [\"Home\",\"Extract & Transform\",\"View\"],\n",
        "                           icons=[\"house-door-fill\",\"tools\",\"card-text\"],\n",
        "                           default_index=0,\n",
        "                           orientation=\"vertical\",\n",
        "                           styles={\"nav-link\": {\"font-size\": \"30px\", \"text-align\": \"centre\", \"margin\": \"0px\",\n",
        "                                                \"--hover-color\": \"#C80101\"},\n",
        "                                   \"icon\": {\"font-size\": \"30px\"},\n",
        "                                   \"container\" : {\"max-width\": \"6000px\"},\n",
        "                                   \"nav-link-selected\": {\"background-color\": \"#C80101\"}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1QD6JbAH7Ew",
        "outputId": "d3243a6d-b3b3-4ec0-a435-0afd4b19bfb2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-02 13:25:39.627 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 13:25:39.637 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 13:25:39.639 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 13:25:39.911 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-12-02 13:25:39.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# MongoDB Atlas connection string\n",
        "client = MongoClient(\"mongodb+srv://ragul:Ragulmanickam@cluster0.adce2.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client.get_database(\"Youtubedata\")  # Replace <database> with your database name\n",
        "\n"
      ],
      "metadata": {
        "id": "7l52HGprH_Ty"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = pymongo.MongoClient(\"localhost:27017\")\n",
        "db = client.Youtube_Data_ragul"
      ],
      "metadata": {
        "id": "p07n9h0JP3s_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydb = sql.connect(host=\"127.0.0.1\",\n",
        "                   user=\"root\",\n",
        "                   password=\"Ragulmanickam@1\",\n",
        "                   database= \"youtube\",\n",
        "                   port = \"3306\"\n",
        "                  )"
      ],
      "metadata": {
        "id": "Ms0lRFleTN8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BUILDING CONNECTION WITH YOUTUBE API\n",
        "api_key = \"AIzaSyB-lfIHiy_Wh0AfSiwrjf9sxzIvKxDBNfk\"\n",
        "youtube = build('youtube','v3',developerKey=api_key)\n"
      ],
      "metadata": {
        "id": "tq9guvXvTQx_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTION TO GET CHANNEL DETAILS\n",
        "def get_channel_details(channel_id):\n",
        "    ch_data = []\n",
        "    response = youtube.channels().list(part = 'snippet,contentDetails,statistics',\n",
        "                                     id= channel_id).execute()\n",
        "\n",
        "    for i in range(len(response['items'])):\n",
        "        data = dict(Channel_id = channel_id[i],\n",
        "                    Channel_name = response['items'][i]['snippet']['title'],\n",
        "                    Playlist_id = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'],\n",
        "                    Subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
        "                    Views = response['items'][i]['statistics']['viewCount'],\n",
        "                    Total_videos = response['items'][i]['statistics']['videoCount'],\n",
        "                    Description = response['items'][i]['snippet']['description'],\n",
        "                    Country = response['items'][i]['snippet'].get('country')\n",
        "                    )\n",
        "        ch_data.append(data)\n",
        "    return ch_data"
      ],
      "metadata": {
        "id": "zPzaFg4fTf_M"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FUNCTION TO GET VIDEO IDS\n",
        "def get_channel_videos(channel_id):\n",
        "    video_ids = []\n",
        "    # get Uploads playlist id\n",
        "    res = youtube.channels().list(id=channel_id,\n",
        "                                  part='contentDetails').execute()\n",
        "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        res = youtube.playlistItems().list(playlistId=playlist_id,\n",
        "                                           part='snippet',\n",
        "                                           maxResults=50,\n",
        "                                           pageToken=next_page_token).execute()\n",
        "\n",
        "        for i in range(len(res['items'])):\n",
        "            video_ids.append(res['items'][i]['snippet']['resourceId']['videoId'])\n",
        "        next_page_token = res.get('nextPageToken')\n",
        "\n",
        "        if next_page_token is None:\n",
        "            break\n",
        "    return video_ids\n"
      ],
      "metadata": {
        "id": "o4C3oVblTl7E"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FUNCTION TO GET VIDEO DETAILS\n",
        "def get_video_details(v_ids):\n",
        "    video_stats = []\n",
        "\n",
        "    for i in range(0, len(v_ids), 50):\n",
        "        response = youtube.videos().list(\n",
        "                    part=\"snippet,contentDetails,statistics\",\n",
        "                    id=','.join(v_ids[i:i+50])).execute()\n",
        "        for video in response['items']:\n",
        "            video_details = dict(Channel_name = video['snippet']['channelTitle'],\n",
        "                                Channel_id = video['snippet']['channelId'],\n",
        "                                Video_id = video['id'],\n",
        "                                Title = video['snippet']['title'],\n",
        "                                Tags = video['snippet'].get('tags'),\n",
        "                                Thumbnail = video['snippet']['thumbnails']['default']['url'],\n",
        "                                Description = video['snippet']['description'],\n",
        "                                Published_date = video['snippet']['publishedAt'],\n",
        "                                Duration = video['contentDetails']['duration'],\n",
        "                                Views = video['statistics']['viewCount'],\n",
        "                                Likes = video['statistics'].get('likeCount'),\n",
        "                                Comments = video['statistics'].get('commentCount'),\n",
        "                                Favorite_count = video['statistics']['favoriteCount'],\n",
        "                                Definition = video['contentDetails']['definition'],\n",
        "                                Caption_status = video['contentDetails']['caption']\n",
        "                               )\n",
        "            video_stats.append(video_details)\n",
        "    return video_stats"
      ],
      "metadata": {
        "id": "0yNSPh0mTrOF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FUNCTION TO GET COMMENT DETAILS\n",
        "def get_comments_details(v_id):\n",
        "    comment_data = []\n",
        "    try:\n",
        "        next_page_token = None\n",
        "        while True:\n",
        "            response = youtube.commentThreads().list(part=\"snippet,replies\",\n",
        "                                                    videoId=v_id,\n",
        "                                                    maxResults=100,\n",
        "                                                    pageToken=next_page_token).execute()\n",
        "            for cmt in response['items']:\n",
        "                data = dict(Comment_id = cmt['id'],\n",
        "                            Video_id = cmt['snippet']['videoId'],\n",
        "                            Comment_text = cmt['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
        "                            Comment_author = cmt['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
        "                            Comment_posted_date = cmt['snippet']['topLevelComment']['snippet']['publishedAt'],\n",
        "                            Like_count = cmt['snippet']['topLevelComment']['snippet']['likeCount'],\n",
        "                            Reply_count = cmt['snippet']['totalReplyCount']\n",
        "                           )\n",
        "                comment_data.append(data)\n",
        "            next_page_token = response.get('nextPageToken')\n",
        "            if next_page_token is None:\n",
        "                break\n",
        "    except:\n",
        "        pass\n",
        "    return comment_data"
      ],
      "metadata": {
        "id": "6PN6HIsoTwaV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTION TO GET CHANNEL NAMES FROM MONGODB\n",
        "def channel_names():\n",
        "    ch_name = []\n",
        "    for i in db.channel_details.find():\n",
        "        ch_name.append(i['Channel_name'])\n",
        "    return ch_name"
      ],
      "metadata": {
        "id": "dW2RC8M1T4ed"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HOME PAGE\n",
        "if selected == \"Home\":\n",
        "    # Title Image\n",
        "    st.image(\"/content/drive/MyDrive/guvi capstone projects/youtube harvesting/title.png\")\n",
        "    col1,col2 = st.columns(2,gap= 'medium')\n",
        "    col1.markdown(\"## :blue[Domain] : Social Media\")\n",
        "    col1.markdown(\"## :blue[Technologies used] : Python,MongoDB, Youtube Data API, MySql, Streamlit\")\n",
        "    col1.markdown(\"## :blue[Overview] : Retrieving the Youtube channels data from the Google API, storing it in a MongoDB as data lake, migrating and transforming data into a SQL database,then querying the data and displaying it in the Streamlit app.\")\n",
        "    col2.markdown(\"#   \")\n",
        "    col2.markdown(\"#   \")\n",
        "    col2.markdown(\"#   \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JRFGuoUT4m4",
        "outputId": "9c94b86e-84a3-4e69-e991-85f7bf6a9608"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-02 07:41:31.759 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.152 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.153 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.155 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.159 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.161 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.164 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.167 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.172 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.181 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.184 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.187 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.189 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.192 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.195 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.207 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-02 07:41:32.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXTRACT AND TRANSFORM PAGE\n",
        "if selected == \"Extract & Transform\":\n",
        "    tab1,tab2 = st.tabs([\"$\\huge 📝 EXTRACT $\", \"$\\huge🚀 TRANSFORM $\"])\n",
        "\n",
        "      # EXTRACT TAB\n",
        "    with tab1:\n",
        "        st.markdown(\"#    \")\n",
        "        st.write(\"### Enter YouTube Channel_ID below :\")\n",
        "        ch_id = st.text_input(\"Hint : Goto channel's home page > Right click > View page source > Find channel_id\").split(',')\n",
        "\n",
        "        if ch_id and st.button(\"Extract Data\"):\n",
        "            ch_details = get_channel_details(ch_id)\n",
        "            st.write(f'#### Extracted data from :green[\"{ch_details[0][\"Channel_name\"]}\"] channel')\n",
        "            st.table(ch_details)\n",
        "\n",
        "        if st.button(\"Upload to MongoDB\"):\n",
        "            with st.spinner('Please Wait for it...'):\n",
        "                ch_details = get_channel_details(ch_id)\n",
        "                v_ids = get_channel_videos(ch_id)\n",
        "                vid_details = get_video_details(v_ids)\n",
        "\n",
        "                def comments():\n",
        "                    com_d = []\n",
        "                    for i in v_ids:\n",
        "                        com_d+= get_comments_details(i)\n",
        "                    return com_d\n",
        "                comm_details = comments()\n",
        "\n",
        "                collections1 = db.channel_details\n",
        "                collections1.insert_many(ch_details)\n",
        "\n",
        "                collections2 = db.video_details\n",
        "                collections2.insert_many(vid_details)\n",
        "\n",
        "                collections3 = db.comments_details\n",
        "                collections3.insert_many(comm_details)\n",
        "                st.success(\"Upload to MongoDB successful !!\")\n",
        "\n",
        "\n",
        "\n",
        "    # TRANSFORM TAB\n",
        "    with tab2:\n",
        "            st.markdown(\"#   \")\n",
        "            st.markdown(\"### Select a channel to begin Transformation to SQL\")\n",
        "            ch_names = channel_names()\n",
        "            user_inp = st.selectbox(\"Select channel\",options= ch_names)\n",
        "\n",
        "    def insert_into_channels():\n",
        "                    collections = db.channel_details\n",
        "                    query = \"\"\"INSERT INTO channels VALUES(%s,%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
        "\n",
        "                    for i in collections.find({\"Channel_name\" : user_inp},{'_id' : 0}):\n",
        "                        mycursor.execute(query,tuple(i.values()))\n",
        "                    mydb.commit()\n",
        "\n",
        "    def insert_into_videos():\n",
        "            collections1 = db.video_details\n",
        "            query1 = \"\"\"INSERT INTO videos VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
        "\n",
        "            for i in collections1.find({\"Channel_name\" : user_inp},{'_id' : 0}):\n",
        "                values = [str(val).replace(\"'\", \"''\").replace('\"', '\"\"') if isinstance(val, str) else val for val in i.values()]\n",
        "                mycursor.execute(query1, tuple(values))\n",
        "                mydb.commit()\n",
        "\n",
        "    def insert_into_comments():\n",
        "            collections1 = db.video_details\n",
        "            collections2 = db.comments_details\n",
        "            query2 = \"\"\"INSERT INTO comments VALUES(%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
        "\n",
        "            for vid in collections1.find({\"Channel_name\" : user_inp},{'_id' : 0}):\n",
        "                for i in collections2.find({'Video_id': vid['Video_id']},{'_id' : 0}):\n",
        "                    mycursor.execute(query2,tuple(i.values()))\n",
        "                    mydb.commit()\n",
        "\n",
        "    if st.button(\"Submit\"):\n",
        "        try:\n",
        "            insert_into_videos()\n",
        "            insert_into_channels()\n",
        "            insert_into_comments()\n",
        "            st.success(\"Transformation to MySQL Successful !!\")\n",
        "        except:\n",
        "            st.error(\"Channel details already transformed !!\")"
      ],
      "metadata": {
        "id": "gxzsWg9pUU-f"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# VIEW PAGE\n",
        "if selected == \"View\":\n",
        "\n",
        "    st.write(\"## :orange[Select any question to get Insights]\")\n",
        "    questions = st.selectbox('Questions',\n",
        "    ['1. What are the names of all the videos and their corresponding channels?',\n",
        "    '2. Which channels have the most number of videos, and how many videos do they have?',\n",
        "    '3. What are the top 10 most viewed videos and their respective channels?',\n",
        "    '4. How many comments were made on each video, and what are their corresponding video names?',\n",
        "    '5. Which videos have the highest number of likes, and what are their corresponding channel names?',\n",
        "    '6. What is the total number of likes and dislikes for each video, and what are their corresponding video names?',\n",
        "    '7. What is the total number of views for each channel, and what are their corresponding channel names?',\n",
        "    '8. What are the names of all the channels that have published videos in the year 2022?',\n",
        "    '9. What is the average duration of all videos in each channel, and what are their corresponding channel names?',\n",
        "    '10. Which videos have the highest number of comments, and what are their corresponding channel names?'])\n",
        "\n",
        "    if questions == '1. What are the names of all the videos and their corresponding channels?':\n",
        "        mycursor.execute(\"\"\"SELECT title AS Video_Title, channel_name AS Channel_Name\n",
        "                            FROM videos\n",
        "                            ORDER BY channel_name\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "\n",
        "    elif questions == '2. Which channels have the most number of videos, and how many videos do they have?':\n",
        "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name, total_videos AS Total_Videos\n",
        "                            FROM channels\n",
        "                            ORDER BY total_videos DESC\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "        st.write(\"### :green[Number of videos in each channel :]\")\n",
        "        #st.bar_chart(df,x= mycursor.column_names[0],y= mycursor.column_names[1])\n",
        "        fig = px.bar(df,\n",
        "                     x=mycursor.column_names[0],\n",
        "                     y=mycursor.column_names[1],\n",
        "                     orientation='v',\n",
        "                     color=mycursor.column_names[0]\n",
        "                    )\n",
        "        st.plotly_chart(fig,use_container_width=True)\n",
        "\n",
        "    elif questions == '3. What are the top 10 most viewed videos and their respective channels?':\n",
        "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name, title AS Video_Title, views AS Views\n",
        "                            FROM videos\n",
        "                            ORDER BY views DESC\n",
        "                            LIMIT 10\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "        st.write(\"### :green[Top 10 most viewed videos :]\")\n",
        "        fig = px.bar(df,\n",
        "                     x=mycursor.column_names[2],\n",
        "                     y=mycursor.column_names[1],\n",
        "                     orientation='h',\n",
        "                     color=mycursor.column_names[0]\n",
        "                    )\n",
        "        st.plotly_chart(fig,use_container_width=True)\n",
        "\n",
        "    elif questions == '4. How many comments were made on each video, and what are their corresponding video names?':\n",
        "        mycursor.execute(\"\"\"SELECT a.video_id AS Video_id, a.title AS Video_Title, b.Total_Comments\n",
        "                            FROM videos AS a\n",
        "                            LEFT JOIN (SELECT video_id,COUNT(comment_id) AS Total_Comments\n",
        "                            FROM comments GROUP BY video_id) AS b\n",
        "                            ON a.video_id = b.video_id\n",
        "                            ORDER BY b.Total_Comments DESC\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "\n",
        "    elif questions == '5. Which videos have the highest number of likes, and what are their corresponding channel names?':\n",
        "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name,title AS Title,likes AS Likes_Count\n",
        "                            FROM videos\n",
        "                            ORDER BY likes DESC\n",
        "                            LIMIT 10\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "        st.write(\"### :green[Top 10 most liked videos :]\")\n",
        "        fig = px.bar(df,\n",
        "                     x=mycursor.column_names[2],\n",
        "                     y=mycursor.column_names[1],\n",
        "                     orientation='h',\n",
        "                     color=mycursor.column_names[0]\n",
        "                    )\n",
        "        st.plotly_chart(fig,use_container_width=True)\n",
        "\n",
        "    elif questions == '6. What is the total number of likes and dislikes for each video, and what are their corresponding video names?':\n",
        "        mycursor.execute(\"\"\"SELECT title AS Title, likes AS Likes_Count\n",
        "                            FROM videos\n",
        "                            ORDER BY likes DESC\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "\n",
        "    elif questions == '7. What is the total number of views for each channel, and what are their corresponding channel names?':\n",
        "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name, views AS Views\n",
        "                            FROM channels\n",
        "                            ORDER BY views DESC\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "        st.write(\"### :green[Channels vs Views :]\")\n",
        "        fig = px.bar(df,\n",
        "                     x=mycursor.column_names[0],\n",
        "                     y=mycursor.column_names[1],\n",
        "                     orientation='v',\n",
        "                     color=mycursor.column_names[0]\n",
        "                    )\n",
        "        st.plotly_chart(fig,use_container_width=True)\n",
        "\n",
        "    elif questions == '8. What are the names of all the channels that have published videos in the year 2022?':\n",
        "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name\n",
        "                            FROM videos\n",
        "                            WHERE published_date LIKE '2022%'\n",
        "                            GROUP BY channel_name\n",
        "                            ORDER BY channel_name\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "\n",
        "    elif questions == '9. What is the average duration of all videos in each channel, and what are their corresponding channel names?':\n",
        "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name,\n",
        "                            AVG(duration)/60 AS \"Average_Video_Duration (mins)\"\n",
        "                            FROM videos\n",
        "                            GROUP BY channel_name\n",
        "                            ORDER BY AVG(duration)/60 DESC\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "        st.write(\"### :green[Avg video duration for channels :]\")\n",
        "        fig = px.bar(df,\n",
        "                     x=mycursor.column_names[0],\n",
        "                     y=mycursor.column_names[1],\n",
        "                     orientation='v',\n",
        "                     color=mycursor.column_names[0]\n",
        "                    )\n",
        "        st.plotly_chart(fig,use_container_width=True)\n",
        "\n",
        "    elif questions == '10. Which videos have the highest number of comments, and what are their corresponding channel names?':\n",
        "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name,video_id AS Video_ID,comments AS Comments\n",
        "                            FROM videos\n",
        "                            ORDER BY comments DESC\n",
        "                            LIMIT 10\"\"\")\n",
        "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
        "        st.write(df)\n",
        "        st.write(\"### :green[Videos with most comments :]\")\n",
        "        fig = px.bar(df,\n",
        "                     x=mycursor.column_names[1],\n",
        "                     y=mycursor.column_names[2],\n",
        "                     orientation='v',\n",
        "                     color=mycursor.column_names[0]\n",
        "                    )\n",
        "        st.plotly_chart(fig,use_container_width=True)\n"
      ],
      "metadata": {
        "id": "imM4wM1XVAr2"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}